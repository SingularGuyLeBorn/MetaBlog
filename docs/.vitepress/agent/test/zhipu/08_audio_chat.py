"""
08. éŸ³é¢‘å¯¹è¯ç¤ºä¾‹
è¯­éŸ³è¾“å…¥å’Œè¾“å‡ºï¼Œå®ç°è‡ªç„¶è¯­éŸ³äº¤äº’
"""
import requests
import base64
from config import ZHIPU_BASE_URL, get_headers, check_api_key, DEFAULT_AUDIO_MODEL

def audio_chat_text_input():
    """æ–‡æœ¬è¾“å…¥ï¼Œè¯­éŸ³è¾“å‡ºï¼ˆç®€åŒ–çš„æ–‡æœ¬å¯¹è¯ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ¤ æµ‹è¯• 1: éŸ³é¢‘æ¨¡å‹æ–‡æœ¬å¯¹è¯")
    print("="*60)
    
    if not check_api_key():
        return
    
    url = f"{ZHIPU_BASE_URL}/chat/completions"
    
    # glm-4-voice æ”¯æŒæ–‡æœ¬è¾“å…¥
    data = {
        "model": DEFAULT_AUDIO_MODEL,  # glm-4-voice
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹ï¼Œå›ç­”è¦å£è¯­åŒ–ã€è‡ªç„¶ã€‚"
            },
            {
                "role": "user",
                "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
            }
        ],
        "temperature": 0.8,
        "stream": False
    }
    
    print(f"\nğŸ“¤ å‘é€è¯·æ±‚:")
    print(f"  æ¨¡å‹: {DEFAULT_AUDIO_MODEL}")
    print(f"  è¾“å…¥: {data['messages'][-1]['content']}")
    
    try:
        response = requests.post(url, headers=get_headers(), json=data, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            print(f"\nğŸ“¥ æ–‡æœ¬å›å¤:\n{content}")
            print("\nğŸ’¡ æ³¨æ„: å®é™…è¯­éŸ³è¾“å‡ºéœ€è¦ä½¿ç”¨ WebSocket å®æ—¶ API")
            print("   è¿™é‡Œåªå±•ç¤ºæ–‡æœ¬å›å¤éƒ¨åˆ†")
        else:
            print(f"\nâŒ è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
    except Exception as e:
        print(f"\nâŒ å¼‚å¸¸: {str(e)}")

def audio_chat_with_audio_input():
    """è¯­éŸ³è¾“å…¥ç¤ºä¾‹ï¼ˆéœ€è¦æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ¤ æµ‹è¯• 2: è¯­éŸ³è¾“å…¥")
    print("="*60)
    
    if not check_api_key():
        return
    
    print("\nğŸ’¡ è¯­éŸ³è¾“å…¥ç¤ºä¾‹ä»£ç :")
    print("""
    # 1. è¯»å–æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ (wav æ ¼å¼)
    with open("input.wav", "rb") as f:
        audio_data = f.read()
    
    # 2. è½¬ä¸º base64
    audio_base64 = base64.b64encode(audio_data).decode("utf-8")
    
    # 3. å‘é€è¯·æ±‚
    data = {
        "model": "glm-4-voice",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": "è¿™æ˜¯æˆ‘çš„è¯­éŸ³é—®é¢˜"},
                {"type": "input_audio", "input_audio": {
                    "data": audio_base64,
                    "format": "wav"
                }}
            ]
        }]
    }
    """)
    
    print("\nâš ï¸  è·³è¿‡å®é™…æµ‹è¯•ï¼ˆéœ€è¦æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ï¼‰")
    print("è¯·å‡†å¤‡ wav æ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶åæµ‹è¯•")

def audio_multimodal_conversation():
    """å¤šæ¨¡æ€éŸ³é¢‘å¯¹è¯"""
    print("\n" + "="*60)
    print("ğŸ¤ æµ‹è¯• 3: å¤šæ¨¡æ€éŸ³é¢‘å¯¹è¯")
    print("="*60)
    
    if not check_api_key():
        return
    
    url = f"{ZHIPU_BASE_URL}/chat/completions"
    
    # ç»“åˆæ–‡æœ¬ã€å›¾ç‰‡å’Œè¯­éŸ³çš„å¤æ‚å¯¹è¯
    print("\nğŸ’¡ å¤šæ¨¡æ€å¯¹è¯ç¤ºä¾‹:")
    print("""
    data = {
        "model": "glm-4-voice",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": "æˆ‘çœ‹è¿™å¼ å›¾ï¼Œæƒ³çŸ¥é“é‡Œé¢çš„å†…å®¹"},
                {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}},
                {"type": "input_audio", "input_audio": {
                    "data": "base64_encoded_audio...",
                    "format": "wav"
                }}
            ]
        }]
    }
    """)
    
    print("\nâš ï¸  å¤šæ¨¡æ€æµ‹è¯•éœ€è¦å‡†å¤‡å›¾ç‰‡å’ŒéŸ³é¢‘æ–‡ä»¶")

def realtime_api_info():
    """å®æ—¶ API ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ğŸ¤ æµ‹è¯• 4: å®æ—¶è¯­éŸ³ API (GLM-Realtime)")
    print("="*60)
    
    print("""
ğŸ’¡ GLM-Realtime æ˜¯æ™ºè°±çš„å®æ—¶éŸ³è§†é¢‘ API

ç‰¹ç‚¹:
- WebSocket è¿æ¥ï¼Œå®æ—¶åŒå‘é€šä¿¡
- æ”¯æŒè§†é¢‘é€šè¯åŠŸèƒ½
- é€šè¯è®°å¿†æ—¶é•¿é•¿è¾¾ 2 åˆ†é’Ÿ
- è·¨æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘å®æ—¶æ¨ç†

ä½¿ç”¨åœºæ™¯:
- å®æ—¶è¯­éŸ³åŠ©æ‰‹
- è§†é¢‘é€šè¯ AI
- å¤šæ¨¡æ€äº¤äº’

è¿æ¥æ–¹å¼:
  wss://open.bigmodel.cn/api/paas/v4/realtime

éœ€è¦é¢å¤–å‚æ•°:
- Authorization: Bearer {API_KEY}
- éŸ³é¢‘æ ¼å¼: pcm, wav
- è§†é¢‘æ ¼å¼: base64 ç¼–ç çš„å¸§

Python ç¤ºä¾‹éœ€è¦ä½¿ç”¨ websockets åº“:
  import websockets
  
  async with websockets.connect(uri, extra_headers=headers) as ws:
      # å‘é€éŸ³é¢‘/è§†é¢‘å¸§
      await ws.send(json.dumps({...}))
      # æ¥æ”¶å“åº”
      response = await ws.recv()

ç”±äºéœ€è¦ WebSocket å’ŒéŸ³è§†é¢‘æµå¤„ç†ï¼Œè¿™é‡Œä»…ä½œè¯´æ˜ã€‚
å®Œæ•´ç¤ºä¾‹è¯·å‚è€ƒæ™ºè°±å®˜æ–¹æ–‡æ¡£ã€‚
""")

def tts_demo():
    """è¯­éŸ³åˆæˆ (TTS) è¯´æ˜"""
    print("\n" + "="*60)
    print("ğŸ¤ æµ‹è¯• 5: è¯­éŸ³åˆæˆ (TTS)")
    print("="*60)
    
    print("""
ğŸ’¡ æ™ºè°±æä¾› GLM-TTS æ¨¡å‹ç”¨äºè¯­éŸ³åˆæˆ

æ¥å£: /paas/v4/async/audio

æ”¯æŒçš„æ¨¡å‹:
- glm-tts: è¶…æ‹Ÿäººè¯­éŸ³åˆæˆï¼Œæƒ…æ„Ÿè¡¨è¾¾å¢å¼º
- glm-tts-clone: éŸ³è‰²å…‹éš†ï¼ˆ3ç§’éŸ³é¢‘å³å¯ï¼‰

æ”¯æŒçš„å‚æ•°:
- voice: éŸ³è‰²ç±»å‹
- speed: è¯­é€Ÿ (0.5-2.0)
- pitch: éŸ³è°ƒ
- emotion: æƒ…æ„Ÿ (neutral, happy, sad, angry)

ç¤ºä¾‹è¯·æ±‚:
    {
        "model": "glm-tts",
        "input": {"text": "ä½ å¥½ï¼Œæˆ‘æ˜¯æ™ºè°±AI"},
        "voice": "xiaowen",
        "speed": 1.0
    }

å“åº”: è¿”å›éŸ³é¢‘æ–‡ä»¶çš„ URL

ç”±äº TTS æ˜¯å¼‚æ­¥æ¥å£ï¼Œéœ€è¦è½®è¯¢è·å–ç»“æœã€‚
""")

if __name__ == '__main__':
    print("\nğŸš€ æ™ºè°± AI - éŸ³é¢‘å¯¹è¯ç¤ºä¾‹")
    print(f"ä½¿ç”¨æ¨¡å‹: {DEFAULT_AUDIO_MODEL}\n")
    
    audio_chat_text_input()
    audio_chat_with_audio_input()
    audio_multimodal_conversation()
    realtime_api_info()
    tts_demo()
    
    print("\n" + "="*60)
    print("âœ… éŸ³é¢‘å¯¹è¯æµ‹è¯•å®Œæˆ!")
    print("="*60)
