# 03-思考模型

## 模型说明

| 模型 | 思考模式 | 说明 |
|:---|:---|:---|
| `kimi-k2.5` | 默认启用，可禁用 | **推荐** - 多功能思考模型 |
| `kimi-k2-thinking` | 强制启用 | 纯文本深度思考 |

## 基础使用

### kimi-k2-thinking（强制思考）

```python
from openai import OpenAI

client = OpenAI(
    api_key="your-api-key",
    base_url="https://api.moonshot.cn/v1",
)

response = client.chat.completions.create(
    model="kimi-k2-thinking",
    messages=[
        {"role": "system", "content": "你是 Kimi。"},
        {"role": "user", "content": "请解释 1+1=2。"}
    ]
)

# 获取思考内容和最终答案
message = response.choices[0].message

# 使用 getattr 获取 reasoning_content
reasoning = getattr(message, "reasoning_content", None)
content = message.content

if reasoning:
    print(f"思考过程：\n{reasoning}\n")
print(f"最终答案：\n{content}")
```

### kimi-k2.5（默认思考）

```python
# kimi-k2.5 默认启用思考能力
response = client.chat.completions.create(
    model="kimi-k2.5",
    messages=[
        {"role": "user", "content": "请解释 1+1=2。"}
    ]
)

message = response.choices[0].message
reasoning = getattr(message, "reasoning_content", None)
content = message.content

if reasoning:
    print(f"思考过程：\n{reasoning}\n")
print(f"最终答案：\n{content}")
```

### kimi-k2.5（禁用思考）

```python
response = client.chat.completions.create(
    model="kimi-k2.5",
    messages=[
        {"role": "user", "content": "请解释 1+1=2。"}
    ],
    extra_body={"thinking": {"type": "disabled"}}
)

# 不会返回 reasoning_content
print(response.choices[0].message.content)
```

## 流式输出处理

```python
response = client.chat.completions.create(
    model="kimi-k2-thinking",
    messages=[{"role": "user", "content": "解释量子计算"}],
    stream=True
)

print("思考过程：")
print("-" * 60)

in_content = False
for chunk in response:
    delta = chunk.choices[0].delta
    
    # 获取 reasoning_content
    reasoning = getattr(delta, "reasoning_content", None)
    if reasoning:
        print(reasoning, end="", flush=True)
    
    # content 在 reasoning_content 之后出现
    if delta.content:
        if not in_content:
            in_content = True
            print("\n\n最终答案：")
            print("-" * 60)
        print(delta.content, end="", flush=True)
```

## 多步工具调用（思考模型）

思考模型支持多步工具调用，**必须遵守以下规则**：

1. 输入必须包含上下文中所有 `reasoning_content`
2. 设置 `max_tokens >= 16000`
3. **设置 `temperature=1.0`**（kimi-k2.5 固定使用 1.0）
4. 使用流式输出 `stream=True`

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "date",
            "description": "获取当前日期"
        }
    },
    {
        "type": "function",
        "function": {
            "name": "web_search",
            "description": "搜索网页内容",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string"}
                },
                "required": ["query"]
            }
        }
    }
]

response = client.chat.completions.create(
    model="kimi-k2-thinking",  # 或启用思考的 kimi-k2.5
    messages=[
        {"role": "system", "content": "你是一个助手，负责生成今日新闻报告。"},
        {"role": "user", "content": "请生成今日的新闻报告。"}
    ],
    tools=tools,
    max_tokens=16000,
    temperature=1.0,
    stream=True
)

# 处理流式响应
for chunk in response:
    delta = chunk.choices[0].delta
    
    reasoning = getattr(delta, "reasoning_content", None)
    if reasoning:
        print(f"[思考] {reasoning}", end="")
    
    if delta.content:
        print(delta.content, end="")
```

## 保留 reasoning_content 的多轮对话

```python
messages = [
    {"role": "user", "content": "今天有什么新闻？"}
]

# 第一轮
response = client.chat.completions.create(
    model="kimi-k2-thinking",
    messages=messages,
    tools=tools,
    max_tokens=16000,
    temperature=1.0
)

message = response.choices[0].message

# 添加助手回复到上下文（包含 reasoning_content）
messages.append({
    "role": "assistant",
    "content": message.content,
    "reasoning_content": getattr(message, "reasoning_content", None),
    "tool_calls": message.tool_calls if hasattr(message, "tool_calls") else None
})

# 添加工具结果
messages.append({
    "role": "tool",
    "tool_call_id": message.tool_calls[0].id,
    "content": "工具执行结果..."
})

# 第二轮
response = client.chat.completions.create(
    model="kimi-k2-thinking",
    messages=messages,
    tools=tools,
    max_tokens=16000,
    temperature=1.0
)
```

> ⚠️ **注意**: reasoning_content 会计入 Token 消耗。
