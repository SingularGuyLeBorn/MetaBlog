{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-å·¥å…·è°ƒç”¨ä¸ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•\n",
    "\n",
    "## GLM-4-Flash-250414 æ¨¡å‹èƒ½åŠ›\n",
    "\n",
    "æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼ŒGLM-4-Flash-250414 å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
    "\n",
    "| èƒ½åŠ› | æ”¯æŒæƒ…å†µ | è¯´æ˜ |\n",
    "|:---|:---:|:---|\n",
    "| **æµå¼è¾“å‡º** | âœ… æ”¯æŒ | å®æ—¶æµå¼å“åº” |\n",
    "| **Function Call** | âœ… æ”¯æŒ | å¼ºå¤§çš„å·¥å…·è°ƒç”¨èƒ½åŠ› |\n",
    "| **ä¸Šä¸‹æ–‡ç¼“å­˜** | âœ… æ”¯æŒ | æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œä¼˜åŒ–é•¿å¯¹è¯ |\n",
    "| **ç»“æ„åŒ–è¾“å‡º** | âœ… æ”¯æŒ | JSON ç­‰ç»“æ„åŒ–æ ¼å¼ |\n",
    "| **MCP** | âœ… æ”¯æŒ | è°ƒç”¨å¤–éƒ¨ MCP å·¥å…· |\n",
    "| **æ€è€ƒæ¨¡å¼** | âŒ ä¸æ”¯æŒ | è¯¥æ¨¡å‹ä¸æ”¯æŒæ·±åº¦æ€è€ƒ |\n",
    "\n",
    "## æ¨¡å‹è§„æ ¼\n",
    "\n",
    "| è§„æ ¼é¡¹ | æ•°å€¼ |\n",
    "|:---|:---|\n",
    "| ä¸Šä¸‹æ–‡çª—å£ | 128K |\n",
    "| å¤šè¯­è¨€æ”¯æŒ | 26ç§è¯­è¨€ |\n",
    "| å®šä½ | æ™ºè°±é¦–ä¸ªå…è´¹å¤§æ¨¡å‹ API |\n",
    "\n",
    "## åŠŸèƒ½ç‰¹è‰²\n",
    "\n",
    "1. **è¶…é•¿ä¸Šä¸‹æ–‡** - 128K ä¸Šä¸‹æ–‡ï¼Œç›¸å½“äº 300 é¡µä¹¦ç±\n",
    "2. **å¤šè¯­è¨€æ”¯æŒ** - æ”¯æŒ 26 ç§è¯­è¨€\n",
    "3. **ç½‘é¡µæ£€ç´¢** - æ”¯æŒå¤–éƒ¨å·¥å…·è°ƒç”¨ï¼Œé€šè¿‡ç½‘ç»œæœç´¢è·å–ä¿¡æ¯\n",
    "\n",
    "## âš ï¸ å…³é”®åŒºåˆ«\n",
    "\n",
    "ä¸ GLM-4.7-Flash çš„ä¸»è¦åŒºåˆ«ï¼š\n",
    "\n",
    "| èƒ½åŠ› | GLM-4-Flash-250414 | GLM-4.7-Flash |\n",
    "|:---|:---:|:---:|\n",
    "| æ€è€ƒæ¨¡å¼ | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |\n",
    "| å·¥å…·è°ƒç”¨ | âœ… æ”¯æŒ | âœ… æ”¯æŒ |\n",
    "| ç»“æ„åŒ–è¾“å‡º | âœ… æ”¯æŒ | âœ… æ”¯æŒ |\n",
    "| ä¸Šä¸‹æ–‡ | 128K | 200K |\n",
    "\n",
    "## æµ‹è¯•å†…å®¹\n",
    "1. ç¯å¢ƒé…ç½®\n",
    "2. åŸºç¡€å¯¹è¯æµ‹è¯•\n",
    "3. Function Callï¼ˆå·¥å…·è°ƒç”¨ï¼‰\n",
    "4. ç»“æ„åŒ–è¾“å‡ºï¼ˆJSONï¼‰\n",
    "5. ç½‘é¡µæ£€ç´¢ï¼ˆWeb Searchï¼‰\n",
    "6. æ™ºèƒ½å†™ä½œ\n",
    "7. æ™ºèƒ½ç¿»è¯‘\n",
    "8. å®ä½“æŠ½å–\n",
    "9. æµå¼è¾“å‡º\n",
    "10. é•¿ä¸Šä¸‹æ–‡æµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "# !pip install openai python-dotenv jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv('VITE_ZHIPU_API_KEY')\n",
    "except:\n",
    "    api_key = None\n",
    "\n",
    "# å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤ API Key\n",
    "if not api_key:\n",
    "    api_key = \"f7ec61a7856a4f4389e037eb588c69df.0pZgcFlTCk9GHCXM\"\n",
    "\n",
    "BASE_URL = \"https://open.bigmodel.cn/api/paas/v4\"\n",
    "\n",
    "# åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "print(\"âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼\")\n",
    "print(f\"æ¨¡å‹ï¼šGLM-4-Flash-250414\")\n",
    "print(f\"æ³¨æ„ï¼šè¯¥æ¨¡å‹ä¸æ”¯æŒæ€è€ƒæ¨¡å¼ï¼Œä½†æ”¯æŒå·¥å…·è°ƒç”¨å’Œç»“æ„åŒ–è¾“å‡º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åŸºç¡€å¯¹è¯æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 ç®€å•é—®å€™\n",
    "print(\"ğŸ’¬ æµ‹è¯•1ï¼šç®€å•é—®å€™\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– æ¨¡å‹å›å¤ï¼š\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"\\nğŸ“Š Tokenä½¿ç”¨ï¼š{response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 é•¿æ–‡æœ¬ç†è§£ï¼ˆæµ‹è¯•128Kä¸Šä¸‹æ–‡ï¼‰\n",
    "print(\"ğŸ“„ æµ‹è¯•2ï¼šé•¿æ–‡æœ¬ç†è§£\\n\")\n",
    "\n",
    "# ç”Ÿæˆä¸€æ®µè¾ƒé•¿çš„æ–‡æœ¬\n",
    "long_text = \"äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼‰ï¼Œè‹±æ–‡ç¼©å†™ä¸ºAIã€‚\" * 50\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹\"},\n",
    "        {\"role\": \"user\", \"content\": f\"è¯·æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š\\n\\n{long_text}\"}\n",
    "    ],\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– æ€»ç»“ç»“æœï¼š\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function Callï¼ˆå·¥å…·è°ƒç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 å®šä¹‰å·¥å…· - å¤©æ°”æŸ¥è¯¢\n",
    "print(\"ğŸ”§ æµ‹è¯•1ï¼šå¤©æ°”æŸ¥è¯¢å·¥å…·è°ƒç”¨\\n\")\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"åŸå¸‚åç§°ï¼Œå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·\"\n",
    "                    },\n",
    "                    \"date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# è¯¢é—®å¤©æ°”\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}\n",
    "    ],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦è§¦å‘å·¥å…·è°ƒç”¨\n",
    "if message.tool_calls:\n",
    "    print(\"ğŸ”” æ¨¡å‹è§¦å‘å·¥å…·è°ƒç”¨ï¼š\")\n",
    "    for tool_call in message.tool_calls:\n",
    "        print(f\"  å·¥å…·ï¼š{tool_call.function.name}\")\n",
    "        print(f\"  å‚æ•°ï¼š{tool_call.function.arguments}\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ‰§è¡Œå·¥å…·\n",
    "        if tool_call.function.name == \"get_weather\":\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            city = args.get(\"city\", \"æœªçŸ¥\")\n",
    "            print(f\"\\nğŸŒ¤ï¸ æ¨¡æ‹Ÿå¤©æ°”æŸ¥è¯¢ç»“æœï¼š{city} ä»Šå¤©æ™´å¤©ï¼Œ25Â°C\")\n",
    "else:\n",
    "    print(\"ğŸ’¬ æ¨¡å‹ç›´æ¥å›ç­”ï¼š\")\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 å¤šä¸ªå·¥å…·ç»„åˆ\n",
    "print(\"\\nğŸ”§ æµ‹è¯•2ï¼šå¤šä¸ªå·¥å…·ç»„åˆ\\n\")\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"æœç´¢ç½‘ç»œä¿¡æ¯\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"æœç´¢å…³é”®è¯\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"è®¡ç®—æ•°å­¦è¡¨è¾¾å¼\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ï¼š2+2\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"æœç´¢ä¸€ä¸‹åŒ—äº¬çš„äººå£ï¼Œç„¶åè®¡ç®—å¦‚æœæ¯äººæ1å…ƒï¼Œæ€»å…±èƒ½æå¤šå°‘é’±ï¼Ÿ\"}\n",
    "    ],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "if message.tool_calls:\n",
    "    print(\"ğŸ”” è§¦å‘çš„å·¥å…·è°ƒç”¨ï¼š\")\n",
    "    for i, tool_call in enumerate(message.tool_calls, 1):\n",
    "        print(f\"\\n{i}. å·¥å…·ï¼š{tool_call.function.name}\")\n",
    "        print(f\"   å‚æ•°ï¼š{tool_call.function.arguments}\")\n",
    "else:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ç»“æ„åŒ–è¾“å‡ºï¼ˆJSONï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 å®ä½“æŠ½å– - ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯\n",
    "print(\"ğŸ“ æµ‹è¯•1ï¼šå®ä½“æŠ½å–\\n\")\n",
    "\n",
    "sample_text = \"\"\"\n",
    "å¼ ä¸‰ï¼Œæ‰‹æœºå·13800138000ï¼Œäº2024å¹´1æœˆ15æ—¥åœ¨åŒ—äº¬è´­ä¹°äº†ä¸€å°MacBook Proï¼Œ\n",
    "ä»·æ ¼ä¸º19999å…ƒï¼Œè®¢å•å·ï¼šORDER20240115001ã€‚\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æŠ½å–åŠ©æ‰‹ï¼Œè¯·ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¾“å‡º\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“ä¿¡æ¯ï¼Œè¾“å‡ºJSONæ ¼å¼ï¼ˆåŒ…å«ï¼šå§“åã€æ‰‹æœºå·ã€æ—¥æœŸã€åœ°ç‚¹ã€å•†å“ã€ä»·æ ¼ã€è®¢å•å·ï¼‰ï¼š\\n\\n{sample_text}\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "print(\"ğŸ“Š æå–ç»“æœï¼š\")\n",
    "try:\n",
    "    json_result = json.loads(result)\n",
    "    print(json.dumps(json_result, indent=2, ensure_ascii=False))\n",
    "except:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 æ³•å¾‹æ–‡ä¹¦åˆ†æï¼ˆå®ä½“æŠ½å–ï¼‰\n",
    "print(\"\\nâš–ï¸ æµ‹è¯•2ï¼šæ³•å¾‹æ–‡ä¹¦åˆ†æ\\n\")\n",
    "\n",
    "legal_text = \"\"\"\n",
    "ä¸­åäººæ°‘å…±å’Œå›½æœ€é«˜äººæ°‘æ³•é™¢\n",
    "æŒ‡å®šç®¡è¾–å†³å®šä¹¦\n",
    "ï¼ˆ2017ï¼‰æœ€é«˜æ³•åˆ‘è¾– 19 å·\n",
    "å…³äºè¢«å‘Šå•ä½åŒ—äº¬ç›˜å¤æ°æŠ•èµ„æœ‰é™å…¬å¸æ¶‰å«Œéª—å–è´·æ¬¾ã€è¢«å‘Šäººå•æ¶›ç­‰å…«äººæ¶‰å«Œéª—å–è´·æ¬¾ã€\n",
    "éª—è´­å¤–æ±‡ã€éå›½å®¶å·¥ä½œäººå‘˜å—è´¿ã€éæ³•æ‹˜ç¦ã€æ•…æ„æ¯åä¼šè®¡å‡­è¯ã€ä¼šè®¡è´¦ç°¿ã€è´¢åŠ¡ä¼šè®¡æŠ¥å‘Šç­‰çŠ¯ç½ªæ¡ˆä»¶ï¼Œ\n",
    "æœ¬é™¢ç»å®¡æŸ¥ï¼Œä¾ç…§ã€Šä¸­åäººæ°‘å…±å’Œå›½åˆ‘äº‹è¯‰è®¼æ³•ã€‹ç¬¬äºŒåå…­æ¡çš„è§„å®šï¼Œå†³å®šå¦‚ä¸‹ï¼š\n",
    "æŒ‡å®šè¾½å®çœå¤§è¿å¸‚è¥¿å²—åŒºäººæ°‘æ³•é™¢ä¾ç…§åˆ‘äº‹ç¬¬ä¸€å®¡ç¨‹åºå¯¹è¯¥æ¡ˆè¿›è¡Œå®¡åˆ¤ã€‚\n",
    "äºŒã€‡ä¸€ä¸ƒå¹´ä¸‰æœˆåä¸ƒæ—¥\n",
    "\"\"\"\n",
    "\n",
    "schema = {\n",
    "    \"çŠ¯ç½ªå®¢ä½“\": {\"æ¶‰åŠå®¢ä½“\": \"string\"},\n",
    "    \"çŠ¯ç½ªä¸»è§‚è¦ä»¶-ç½ªè¿‡å½¢å¼\": {\"æ•…æ„\": \"string\", \"è¿‡å¤±\": \"string\"},\n",
    "    \"çŠ¯ç½ªä¸»è§‚è¦ä»¶\": {\"çŠ¯ç½ªåŠ¨æœº\": \"string\", \"çŠ¯ç½ªç›®çš„\": \"string\"},\n",
    "    \"çŠ¯ç½ªå®¢è§‚è¦ä»¶\": {\"çŠ¯ç½ªåœ°ç‚¹\": \"string\", \"çŠ¯ç½ªè¡Œä¸º\": \"string\"},\n",
    "    \"é€‚ç”¨æ³•æ¡\": \"string\",\n",
    "    \"åˆ¤å†³ç»“æœæ—¶é—´\": \"string\"\n",
    "}\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"ä½ æ˜¯ä¸€ä¸ªæ³•å¾‹ä¸“å®¶ï¼Œè¯·åˆ†æåˆ¤å†³ä¹¦å†…å®¹å¹¶æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š{json.dumps(schema, ensure_ascii=False)}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"è¯·åˆ†æè¿™ç¯‡åˆ¤å†³ä¹¦ï¼š\\n\\n{legal_text}\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "print(\"ğŸ“Š åˆ†æç»“æœï¼š\")\n",
    "try:\n",
    "    json_result = json.loads(result)\n",
    "    print(json.dumps(json_result, indent=2, ensure_ascii=False))\n",
    "except:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ™ºèƒ½å†™ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆ\n",
    "print(\"âœï¸ æµ‹è¯•ï¼šå°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆ\\n\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "ä¸Šä¸‹æ–‡ï¼šæˆ‘æƒ³æ¨å¹¿å…¬å¸çš„æ–°äº§å“ã€‚æˆ‘çš„å…¬å¸åä¸ºï¼šæ™ºè°±AIï¼Œæ–°äº§å“åä¸ºï¼šChatGLM å¤§æ¨¡å‹ï¼Œæ˜¯ä¸€æ¬¾é¢å‘å¤§ä¼—çš„ AI äº§å“ã€‚\n",
    "ç›®æ ‡ï¼šå¸®æˆ‘åˆ›å»ºä¸€æ¡å°çº¢ä¹¦å¹³å°çš„å¸–å­ï¼Œç›®çš„æ˜¯å¸å¼•äººä»¬ç‚¹å‡»äº§å“é“¾æ¥è¿›è¡Œå­¦ä¹ å’Œä½“éªŒã€‚\n",
    "é£æ ¼ï¼šå‚ç…§Dysonç­‰æˆåŠŸå…¬å¸çš„å®£ä¼ é£æ ¼ï¼ŒåŒæ—¶ç»“åˆå°çº¢ä¹¦çš„æ–‡æ¡ˆé£æ ¼ã€‚\n",
    "è¯­è°ƒï¼šè¯´æœæ€§\n",
    "å—ä¼—ï¼šAI äº§å“åœ¨å°çº¢ä¹¦ä¸Šçš„ä¸»è¦å—ä¼—æ˜¯å¹´è½»äººï¼Œæ´»è·ƒåœ¨äº’è”ç½‘å’Œ AI é¢†åŸŸã€‚\n",
    "å“åº”ï¼šä¿æŒå°çº¢ä¹¦å¸–å­ç®€æ´è€Œæ·±å…·å½±å“åŠ›ï¼Œæ³¨æ„è¦ä½¿ç”¨emojiè¡¨æƒ…ã€‚\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤åª’ä½“æ–‡æ¡ˆæ’°å†™ä¸“å®¶ï¼Œæ“…é•¿åˆ›ä½œå¸å¼•äººçš„å°çº¢ä¹¦å†…å®¹\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ ç”Ÿæˆçš„å°çº¢ä¹¦æ–‡æ¡ˆï¼š\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ™ºèƒ½ç¿»è¯‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 æ–‡å­¦ç¿»è¯‘\n",
    "print(\"ğŸŒ æµ‹è¯•ï¼šæ–‡å­¦ç¿»è¯‘ï¼ˆèå£«æ¯”äºšï¼‰\\n\")\n",
    "\n",
    "text_to_translate = \"\"\"\n",
    "To be, or not to be: that is the question:\n",
    "Whether 'tis nobler in the mind to suffer\n",
    "The slings and arrows of outrageous fortune,\n",
    "Or to take arms against a sea of troubles\n",
    "And by opposing end them.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡å­¦ç¿»è¯‘å®¶ï¼Œæ“…é•¿å°†è‹±æ–‡æ–‡å­¦ä½œå“ç¿»è¯‘æˆæµç•…ã€ä¼˜é›…çš„ä¸­æ–‡\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"è¯·å°†ä»¥ä¸‹èå£«æ¯”äºšæˆå‰§ã€Šå“ˆå§†é›·ç‰¹ã€‹ä¸­çš„ç»å…¸ç‹¬ç™½ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒæ–‡å­¦æ€§å’Œä¼˜é›…ï¼š\\n\\n{text_to_translate}\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ åŸæ–‡ï¼š\")\n",
    "print(text_to_translate)\n",
    "print(\"\\nğŸŒ ç¿»è¯‘ï¼š\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 å¤šè¯­è¨€ç¿»è¯‘æµ‹è¯•\n",
    "print(\"\\nğŸŒ æµ‹è¯•ï¼šå¤šè¯­è¨€ç¿»è¯‘\\n\")\n",
    "\n",
    "languages = [\"è‹±è¯­\", \"æ—¥è¯­\", \"æ³•è¯­\", \"è¥¿ç­ç‰™è¯­\"]\n",
    "text = \"äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼\"\n",
    "\n",
    "print(f\"åŸæ–‡ï¼š{text}\\n\")\n",
    "\n",
    "for lang in languages:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4-flash-250414\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"è¯·å°†ä»¥ä¸‹ä¸­æ–‡ç¿»è¯‘æˆ{lang}ï¼š{text}\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=256\n",
    "    )\n",
    "    print(f\"{lang}ï¼š{response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æµå¼è¾“å‡ºæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 æµå¼è¾“å‡º\n",
    "print(\"ğŸŒŠ æµ‹è¯•ï¼šæµå¼è¾“å‡º\\n\")\n",
    "print(\"ğŸ¤– æ¨¡å‹å›å¤ï¼š\", end=\"\", flush=True)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-flash-250414\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"è¯·å†™ä¸€æ®µå…³äºäººå·¥æ™ºèƒ½çš„ç®€çŸ­ä»‹ç»\"}\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\nâœ… æµå¼è¾“å‡ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘               GLM-4-Flash-250414 æµ‹è¯•æ€»ç»“                      â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ æ¨¡å‹å®šä½ï¼šæ™ºè°±é¦–ä¸ªå…è´¹å¤§æ¨¡å‹ API                                 â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ æ ¸å¿ƒèƒ½åŠ›ï¼š                                                      â•‘\n",
    "â•‘   âœ… æµå¼è¾“å‡º - å®æ—¶å“åº”                                        â•‘\n",
    "â•‘   âœ… Function Call - å¼ºå¤§çš„å·¥å…·è°ƒç”¨èƒ½åŠ›                          â•‘\n",
    "â•‘   âœ… ä¸Šä¸‹æ–‡ç¼“å­˜ - ä¼˜åŒ–é•¿å¯¹è¯æ€§èƒ½                                 â•‘\n",
    "â•‘   âœ… ç»“æ„åŒ–è¾“å‡º - JSON æ ¼å¼è¾“å‡º                                 â•‘\n",
    "â•‘   âœ… MCP - å¤–éƒ¨å·¥å…·è°ƒç”¨                                         â•‘\n",
    "â•‘   âŒ æ€è€ƒæ¨¡å¼ - ä¸æ”¯æŒæ·±åº¦æ€è€ƒ                                   â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ åŠŸèƒ½ç‰¹è‰²ï¼š                                                      â•‘\n",
    "â•‘   â€¢ è¶…é•¿ä¸Šä¸‹æ–‡ - 128Kï¼ˆç›¸å½“äº 300 é¡µä¹¦ç±ï¼‰                       â•‘\n",
    "â•‘   â€¢ å¤šè¯­è¨€æ”¯æŒ - æ”¯æŒ 26 ç§è¯­è¨€                                 â•‘\n",
    "â•‘   â€¢ ç½‘é¡µæ£€ç´¢ - æ”¯æŒå¤–éƒ¨å·¥å…·è°ƒç”¨è·å–ç½‘ç»œä¿¡æ¯                      â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ é€‚ç”¨åœºæ™¯ï¼š                                                      â•‘\n",
    "â•‘   â€¢ æ™ºèƒ½å†™ä½œ - å°çº¢ä¹¦æ–‡æ¡ˆã€å•†ä¸šæ–‡æ¡ˆã€æ–‡å­¦åˆ›ä½œ                    â•‘\n",
    "â•‘   â€¢ æ™ºèƒ½ç¿»è¯‘ - å¤šè¯­è¨€äº’è¯‘ã€æ–‡å­¦ç¿»è¯‘                              â•‘\n",
    "â•‘   â€¢ å®ä½“æŠ½å– - ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®                    â•‘\n",
    "â•‘   â€¢ å·¥å…·è°ƒç”¨ - å¤©æ°”æŸ¥è¯¢ã€æœç´¢ã€è®¡ç®—ç­‰                            â•‘\n",
    "â•‘   â€¢ é•¿æ–‡æœ¬å¤„ç† - æ‘˜è¦ç”Ÿæˆã€æ–‡æ¡£åˆ†æ                              â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ ä¸ GLM-4.7-Flash çš„åŒºåˆ«ï¼š                                      â•‘\n",
    "â•‘   â€¢ GLM-4-Flash-250414ï¼šä¸æ”¯æŒæ€è€ƒæ¨¡å¼ï¼Œä½†åŠŸèƒ½å…¨é¢              â•‘\n",
    "â•‘   â€¢ GLM-4.7-Flashï¼šæ”¯æŒæ€è€ƒæ¨¡å¼ï¼Œä¸Šä¸‹æ–‡æ›´å¤§ï¼ˆ200Kï¼‰             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
