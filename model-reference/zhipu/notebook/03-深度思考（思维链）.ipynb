{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-æ·±åº¦æ€è€ƒï¼ˆæ€ç»´é“¾ï¼‰æµ‹è¯•\n",
    "\n",
    "## GLM-4.1V-Thinking-Flash æ¨¡å‹èƒ½åŠ›\n",
    "\n",
    "æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼ŒGLM-4.1V-Thinking-Flash å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
    "\n",
    "| èƒ½åŠ› | æ”¯æŒæƒ…å†µ | è¯´æ˜ |\n",
    "|:---|:---:|:---|\n",
    "| **å†…ç½®æ·±åº¦æ€è€ƒ** | âœ… å†…ç½® | é»˜è®¤å†…ç½®ï¼Œ**å¼ºåˆ¶æ€è€ƒ**ï¼Œå§‹ç»ˆè¿”å›æ€ç»´é“¾ |\n",
    "| **è§†è§‰ç†è§£** | âœ… æ”¯æŒ | æ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€æ–‡ä»¶ |\n",
    "| **æµå¼è¾“å‡º** | âœ… æ”¯æŒ | å®æ—¶æµå¼å“åº” |\n",
    "\n",
    "## æ¨¡å‹è§„æ ¼\n",
    "\n",
    "| è§„æ ¼é¡¹ | æ•°å€¼ |\n",
    "|:---|:---|\n",
    "| è¾“å…¥æ¨¡æ€ | å›¾åƒã€è§†é¢‘ã€æ–‡ä»¶ã€æ–‡æœ¬ |\n",
    "| è¾“å‡ºæ¨¡æ€ | æ–‡æœ¬ |\n",
    "| ä¸Šä¸‹æ–‡çª—å£ | 64K |\n",
    "| æ€è€ƒæ¨¡å¼ | **å¼ºåˆ¶æ€è€ƒ**ï¼ˆä¸å¯å…³é—­ï¼‰ |\n",
    "\n",
    "## âš ï¸ å…³é”®åŒºåˆ«\n",
    "\n",
    "ä¸ GLM-4.6V-Flash çš„åŒºåˆ«ï¼š\n",
    "\n",
    "| æ¨¡å‹ | æ€è€ƒæ¨¡å¼ | æ§åˆ¶æ–¹å¼ |\n",
    "|:---|:---|:---|\n",
    "| GLM-4.1V-Thinking-Flash | **å†…ç½®** | å¼ºåˆ¶æ€è€ƒï¼Œå§‹ç»ˆè¿”å› reasoning_content |\n",
    "| GLM-4.6V-Flash | **å¯é€‰** | å¯é€šè¿‡ `thinking` å‚æ•°å¼€å¯/å…³é—­ |\n",
    "\n",
    "## åŠŸèƒ½ç‰¹è‰²\n",
    "\n",
    "1. **å›¾æ–‡ç†è§£** - ç²¾å‡†è¯†åˆ«å¹¶ç»¼åˆåˆ†æå›¾åƒä¸æ–‡æœ¬ä¿¡æ¯\n",
    "2. **æ•°å­¦ä¸ç§‘å­¦æ¨ç†** - æ”¯æŒå¤æ‚é¢˜è§£ã€å¤šæ­¥æ¼”ç»ä¸å…¬å¼ç†è§£\n",
    "3. **è§†é¢‘ç†è§£** - å…·å¤‡æ—¶åºåˆ†æä¸äº‹ä»¶é€»è¾‘å»ºæ¨¡èƒ½åŠ›\n",
    "4. **GUI ä¸ç½‘é¡µæ™ºèƒ½ä½“ä»»åŠ¡** - ç†è§£ç•Œé¢ç»“æ„ï¼Œè¾…åŠ©è‡ªåŠ¨åŒ–æ“ä½œ\n",
    "5. **è§†è§‰é”šå®šä¸å®ä½“å®šä½** - è¯­è¨€ä¸å›¾åƒåŒºåŸŸç²¾å‡†å¯¹é½\n",
    "\n",
    "## æµ‹è¯•å†…å®¹\n",
    "1. ç¯å¢ƒé…ç½®\n",
    "2. å›¾ç‰‡é—®ç­”ï¼ˆå›¾è¡¨åˆ†æï¼‰\n",
    "3. å­¦ç§‘è§£é¢˜ï¼ˆæ•°å­¦æ¨ç†ï¼‰\n",
    "4. GUI Agent ä»»åŠ¡\n",
    "5. å‰ç«¯ç½‘é¡µ Coding\n",
    "6. è§†é¢‘ç†è§£ + æ€ç»´é“¾\n",
    "7. æµå¼è¾“å‡º + æ€ç»´é“¾\n",
    "8. é”™è¯¯å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "# !pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv('VITE_ZHIPU_API_KEY')\n",
    "except:\n",
    "    api_key = None\n",
    "\n",
    "# å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤ API Key\n",
    "if not api_key:\n",
    "    api_key = \"f7ec61a7856a4f4389e037eb588c69df.0pZgcFlTCk9GHCXM\"\n",
    "\n",
    "BASE_URL = \"https://open.bigmodel.cn/api/paas/v4\"\n",
    "\n",
    "# åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "# æµ‹è¯•å›¾ç‰‡\n",
    "CHART_IMAGE = \"https://cdn.bigmodel.cn/markdown/1751371892938image.png\"\n",
    "MATH_IMAGE = \"https://cdn.bigmodel.cn/markdown/1751371905445image.png\"\n",
    "GUI_IMAGE = \"https://cdn.bigmodel.cn/markdown/1751371916542image.png\"\n",
    "WEB_IMAGE = \"https://cdn.bigmodel.cn/markdown/1751371942040image.png\"\n",
    "\n",
    "print(\"âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼\")\n",
    "print(f\"æ¨¡å‹ï¼šGLM-4.1V-Thinking-Flash\")\n",
    "print(f\"ç‰¹ç‚¹ï¼šå†…ç½®æ·±åº¦æ€è€ƒï¼ˆå¼ºåˆ¶æ€è€ƒï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å›¾ç‰‡é—®ç­”ï¼ˆå›¾è¡¨åˆ†æï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 å›¾è¡¨åˆ†æ - æ‰¾å‡ºå¹´åº¦åˆ©æ¶¦æœ€é«˜çš„å…¬å¸\n",
    "print(\"ğŸ“Š æµ‹è¯•ï¼šå›¾è¡¨åˆ†æ - å…¬å¸åˆ©æ¶¦åˆ†æ\\n\")\n",
    "print(\"é—®é¢˜ï¼šè¯·æ‰¾å‡ºè¿™å¼ å›¾ä¸­å¹´åº¦åˆ©æ¶¦æœ€é«˜çš„å…¬å¸ï¼Œä»¥åŠè¯¥å…¬å¸çš„æœ€å¤§éƒ¨é—¨ï¼Ÿ\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4.1v-thinking-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": CHART_IMAGE}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"è¯·æ‰¾å‡ºè¿™å¼ å›¾ä¸­å¹´åº¦åˆ©æ¶¦æœ€é«˜çš„å…¬å¸ï¼Œä»¥åŠè¯¥å…¬å¸çš„æœ€å¤§éƒ¨é—¨ï¼Ÿ\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "# æ˜¾ç¤ºæ€ç»´é“¾\n",
    "if hasattr(message, 'reasoning_content') and message.reasoning_content:\n",
    "    print(\"ğŸ§  æ€ç»´é“¾ï¼ˆæ¨ç†è¿‡ç¨‹ï¼‰ï¼š\")\n",
    "    print(\"-\" * 60)\n",
    "    print(message.reasoning_content)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ æœ€ç»ˆç­”æ¡ˆï¼š\")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å­¦ç§‘è§£é¢˜ï¼ˆæ•°å­¦æ¨ç†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 å‡ ä½•é¢˜è§£ç­”\n",
    "print(\"ğŸ“ æµ‹è¯•ï¼šå‡ ä½•é¢˜è§£ç­”\\n\")\n",
    "print(\"é—®é¢˜ï¼šè¯·å¸®æˆ‘è§£å†³è¿™ä¸ªé¢˜ç›®ï¼Œç»™å‡ºè¯¦ç»†è¿‡ç¨‹å’Œç­”æ¡ˆ\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4.1v-thinking-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": MATH_IMAGE}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"è¯·å¸®æˆ‘è§£å†³è¿™ä¸ªå‡ ä½•é¢˜ç›®ï¼Œç»™å‡ºè¯¦ç»†æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "# æ˜¾ç¤ºæ€ç»´é“¾\n",
    "if hasattr(message, 'reasoning_content') and message.reasoning_content:\n",
    "    print(\"ğŸ§  æ€ç»´é“¾ï¼ˆè§£é¢˜æ€è·¯ï¼‰ï¼š\")\n",
    "    print(\"-\" * 60)\n",
    "    print(message.reasoning_content)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ å®Œæ•´è§£ç­”ï¼š\")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GUI Agent ä»»åŠ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 GUI æ“ä½œç†è§£\n",
    "print(\"ğŸ“± æµ‹è¯•ï¼šGUI Agent ä»»åŠ¡\\n\")\n",
    "print(\"é—®é¢˜ï¼šåœ¨ APP ä¸­ï¼Œå¸®æˆ‘åˆ›å»ºä¸€ä¸ªä¸¤å‘¨å 3 ç‚¹ä¸å²å¯†æ–¯åšå£«çš„ä¼šè®®\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4.1v-thinking-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": GUI_IMAGE}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"åœ¨ APP ä¸­ï¼Œå¸®æˆ‘åˆ›å»ºä¸€ä¸ªä¸¤å‘¨å 3 ç‚¹ä¸å²å¯†æ–¯åšå£«çš„ä¼šè®®ã€‚è¯·åˆ†æå½“å‰ç•Œé¢ï¼Œå¹¶ç»™å‡ºæ“ä½œæ­¥éª¤\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "# æ˜¾ç¤ºæ€ç»´é“¾\n",
    "if hasattr(message, 'reasoning_content') and message.reasoning_content:\n",
    "    print(\"ğŸ§  æ€ç»´é“¾ï¼ˆç•Œé¢åˆ†æï¼‰ï¼š\")\n",
    "    print(\"-\" * 60)\n",
    "    print(message.reasoning_content)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ æ“ä½œæ­¥éª¤ï¼š\")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å‰ç«¯ç½‘é¡µ Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 å‰ç«¯ä»£ç ç”Ÿæˆ\n",
    "print(\"ğŸ’» æµ‹è¯•ï¼šå‰ç«¯ç½‘é¡µ Coding\\n\")\n",
    "print(\"é—®é¢˜ï¼šè¯·æ„å»ºä¸€ä¸ªä¸è¾“å…¥å›¾ç‰‡ç›¸ä¼¼çš„ç½‘é¡µå¹¶å°†å…¶è½¬æ¢ä¸º React ä»£ç \\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4.1v-thinking-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": WEB_IMAGE}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"è¯·æ„å»ºä¸€ä¸ªä¸è¾“å…¥å›¾ç‰‡ç›¸ä¼¼çš„ç½‘é¡µå¹¶å°†å…¶è½¬æ¢ä¸º React ä»£ç ã€‚è¯·åˆ†æè®¾è®¡å…ƒç´ ï¼Œç„¶åç»™å‡ºå®Œæ•´ä»£ç \"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=8192\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "# æ˜¾ç¤ºæ€ç»´é“¾\n",
    "if hasattr(message, 'reasoning_content') and message.reasoning_content:\n",
    "    print(\"ğŸ§  æ€ç»´é“¾ï¼ˆè®¾è®¡åˆ†æï¼‰ï¼š\")\n",
    "    print(\"-\" * 60)\n",
    "    print(message.reasoning_content[:1000] + \"...\" if len(message.reasoning_content) > 1000 else message.reasoning_content)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ React ä»£ç ï¼š\")\n",
    "print(message.content[:2000] + \"...\" if len(message.content) > 2000 else message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è§†è§‰é”šå®šä¸å®ä½“å®šä½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 ç‰©ä½“å®šä½æµ‹è¯•\n",
    "print(\"ğŸ“ æµ‹è¯•ï¼šè§†è§‰é”šå®šä¸å®ä½“å®šä½\\n\")\n",
    "\n",
    "# ä½¿ç”¨ä¸€ä¸ªç¤ºä¾‹å›¾ç‰‡ URL\n",
    "LOC_IMAGE = \"https://cloudcovert-1305175928.cos.ap-guangzhou.myqcloud.com/%E5%9B%BE%E7%89%87grounding.PNG\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4.1v-thinking-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": LOC_IMAGE}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Where is the second bottle of beer from the right on the table? Provide coordinates in [[xmin,ymin,xmax,ymax]] format\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "# æ˜¾ç¤ºæ€ç»´é“¾\n",
    "if hasattr(message, 'reasoning_content') and message.reasoning_content:\n",
    "    print(\"ğŸ§  æ€ç»´é“¾ï¼ˆå®šä½åˆ†æï¼‰ï¼š\")\n",
    "    print(\"-\" * 60)\n",
    "    print(message.reasoning_content)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ å®šä½ç»“æœï¼š\")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æµå¼è¾“å‡º + æ€ç»´é“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 æµå¼è¾“å‡ºæµ‹è¯•\n",
    "print(\"ğŸŒŠ æµ‹è¯•ï¼šæµå¼è¾“å‡º + æ€ç»´é“¾\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4.1v-thinking-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": CHART_IMAGE}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"åˆ†æè¿™å¼ å›¾è¡¨çš„ä¸»è¦è¶‹åŠ¿\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  æ€ç»´é“¾ï¼š\")\n",
    "print(\"-\" * 60)\n",
    "reasoning_parts = []\n",
    "content_parts = []\n",
    "\n",
    "for chunk in response:\n",
    "    delta = chunk.choices[0].delta\n",
    "    \n",
    "    # è·å–æ€ç»´é“¾\n",
    "    if hasattr(delta, 'reasoning_content') and delta.reasoning_content:\n",
    "        print(delta.reasoning_content, end=\"\", flush=True)\n",
    "        reasoning_parts.append(delta.reasoning_content)\n",
    "    \n",
    "    # è·å–æœ€ç»ˆå†…å®¹\n",
    "    if delta.content:\n",
    "        content_parts.append(delta.content)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nğŸ’¡ æœ€ç»ˆåˆ†æï¼š\")\n",
    "print(\"\".join(content_parts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. å¯¹æ¯”æµ‹è¯•ï¼šGLM-4.6V-Flash vs GLM-4.1V-Thinking-Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹åœ¨ç›¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°\n",
    "print(\"ğŸ“Š å¯¹æ¯”æµ‹è¯•ï¼šä¸¤ä¸ªè§†è§‰æ¨¡å‹çš„æ¨ç†èƒ½åŠ›\\n\")\n",
    "\n",
    "test_question = \"è¿™å¼ å›¾è¡¨å±•ç¤ºäº†å‡ å®¶å…¬å¸çš„ä»€ä¹ˆæ•°æ®ï¼Ÿæ•°æ®ä¹‹é—´æœ‰ä»€ä¹ˆå…³è”ï¼Ÿ\"\n",
    "\n",
    "models = [\n",
    "    (\"GLM-4.6V-Flash (æ— æ€è€ƒ)\", \"glm-4.6v-flash\", {\"thinking\": {\"type\": \"disabled\"}}),\n",
    "    (\"GLM-4.6V-Flash (æœ‰æ€è€ƒ)\", \"glm-4.6v-flash\", {\"thinking\": {\"type\": \"enabled\"}}),\n",
    "    (\"GLM-4.1V-Thinking-Flash (å¼ºåˆ¶æ€è€ƒ)\", \"glm-4.1v-thinking-flash\", {})\n",
    "]\n",
    "\n",
    "for name, model_code, extra_params in models:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ¤– æ¨¡å‹ï¼š{name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_code,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": CHART_IMAGE}},\n",
    "                        {\"type\": \"text\", \"text\": test_question}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=2048,\n",
    "            **extra_params\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æœ‰æ€ç»´é“¾\n",
    "        has_reasoning = hasattr(message, 'reasoning_content') and message.reasoning_content\n",
    "        \n",
    "        if has_reasoning:\n",
    "            print(f\"ğŸ§  æ€ç»´é“¾é•¿åº¦ï¼š{len(message.reasoning_content)} å­—ç¬¦\")\n",
    "            print(f\"ğŸ’¡ ç­”æ¡ˆé•¿åº¦ï¼š{len(message.content)} å­—ç¬¦\")\n",
    "        else:\n",
    "            print(f\"âŒ æ— æ€ç»´é“¾\")\n",
    "            print(f\"ğŸ’¡ ç­”æ¡ˆé•¿åº¦ï¼š{len(message.content)} å­—ç¬¦\")\n",
    "        \n",
    "        print(f\"\\nå›ç­”é¢„è§ˆï¼š{message.content[:200]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯ï¼š{e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ“Š å¯¹æ¯”æ€»ç»“ï¼š\")\n",
    "print(\"â€¢ GLM-4.6V-Flash (æ— æ€è€ƒ)ï¼šç›´æ¥å›ç­”ï¼Œæ— æ¨ç†è¿‡ç¨‹\")\n",
    "print(\"â€¢ GLM-4.6V-Flash (æœ‰æ€è€ƒ)ï¼šå¯é€‰å¼€å¯æ€ç»´é“¾\")\n",
    "print(\"â€¢ GLM-4.1V-Thinking-Flashï¼šå¼ºåˆ¶æ€è€ƒï¼Œå§‹ç»ˆè¿”å›æ€ç»´é“¾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              GLM-4.1V-Thinking-Flash æµ‹è¯•æ€»ç»“                  â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ æ¨¡å‹å®šä½ï¼šå…è´¹è§†è§‰æ¨ç†æ¨¡å‹ï¼Œå¼ºåˆ¶æ€è€ƒæ¨¡å¼                         â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ æ ¸å¿ƒèƒ½åŠ›ï¼š                                                      â•‘\n",
    "â•‘   âœ… å†…ç½®æ·±åº¦æ€è€ƒ - å¼ºåˆ¶æ€è€ƒï¼Œå§‹ç»ˆè¿”å› reasoning_content         â•‘\n",
    "â•‘   âœ… è§†è§‰ç†è§£ - æ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€æ–‡ä»¶                            â•‘\n",
    "â•‘   âœ… æµå¼è¾“å‡º - å®æ—¶å“åº”                                        â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ åŠŸèƒ½ç‰¹è‰²ï¼š                                                      â•‘\n",
    "â•‘   â€¢ å›¾æ–‡ç†è§£ - ç²¾å‡†è¯†åˆ«å›¾åƒä¸æ–‡æœ¬ä¿¡æ¯                           â•‘\n",
    "â•‘   â€¢ æ•°å­¦ä¸ç§‘å­¦æ¨ç† - å¤æ‚é¢˜è§£ã€å¤šæ­¥æ¼”ç»                         â•‘\n",
    "â•‘   â€¢ è§†é¢‘ç†è§£ - æ—¶åºåˆ†æä¸äº‹ä»¶é€»è¾‘å»ºæ¨¡                           â•‘\n",
    "â•‘   â€¢ GUI Agent - ç•Œé¢ç†è§£ä¸è‡ªåŠ¨åŒ–æ“ä½œ                            â•‘\n",
    "â•‘   â€¢ å‰ç«¯ Coding - è®¾è®¡ç¨¿åˆ°ä»£ç çš„è½¬æ¢                            â•‘\n",
    "â•‘   â€¢ è§†è§‰é”šå®š - è¯­è¨€ä¸å›¾åƒåŒºåŸŸç²¾å‡†å¯¹é½                           â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ é€‚ç”¨åœºæ™¯ï¼š                                                      â•‘\n",
    "â•‘   â€¢ éœ€è¦è¯¦ç»†æ¨ç†è¿‡ç¨‹çš„è§†è§‰åˆ†æä»»åŠ¡                              â•‘\n",
    "â•‘   â€¢ æ•°å­¦/ç§‘å­¦é¢˜ç›®è§£ç­”ï¼ˆéœ€è¦å±•ç¤ºè§£é¢˜æ€è·¯ï¼‰                        â•‘\n",
    "â•‘   â€¢ GUI è‡ªåŠ¨åŒ–ä»»åŠ¡ï¼ˆéœ€è¦åˆ†æç•Œé¢ç»“æ„ï¼‰                          â•‘\n",
    "â•‘   â€¢ å‰ç«¯å¼€å‘ï¼ˆéœ€è¦ç†è§£è®¾è®¡æ„å›¾å¹¶ç”Ÿæˆä»£ç ï¼‰                       â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ ä¸ GLM-4.6V-Flash çš„åŒºåˆ«ï¼š                                      â•‘\n",
    "â•‘   â€¢ GLM-4.1V-Thinking-Flashï¼šå¼ºåˆ¶æ€è€ƒï¼Œæ›´é€‚åˆæ¨ç†ä»»åŠ¡           â•‘\n",
    "â•‘   â€¢ GLM-4.6V-Flashï¼šæ€è€ƒå¯é€‰ï¼Œæ›´çµæ´»ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨               â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
