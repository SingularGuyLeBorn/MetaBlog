# 图片理解 (Vision)

## 功能介绍

图片理解（Vision）让模型能够分析图像内容，回答关于图片的问题。智谱 AI 提供了多个支持图像理解的模型，它们在推理能力、图片数量支持和功能特性上有所不同。

### 模型对比

| 模型 | 模型代码 | 上下文 | 最大输出 | 思考模式 | 思维链支持 | 图片数量限制 | Base64支持 |
|:---|:---|:---:|:---:|:---:|:---:|:---:|:---:|
| GLM-4.6V-Flash | glm-4.6v-flash | 128K | 32K | ✅ 支持 | ✅ 支持 | 50张 | ✅ 支持 |
| GLM-4.1V-Thinking-Flash | glm-4.1v-thinking-flash | 64K | 16K | ✅ 内置 | ✅ 支持 | 50张 | ✅ 支持 |
| GLM-4V-Flash | glm-4v-flash | 16K | 1K | ❌ 不支持 | ❌ 不支持 | **1张** | ❌ 不支持 |

**⚠️ 重要限制说明：**
- **GLM-4V-Flash** 仅支持 **1 张图片**，且 **不支持 Base64 编码**，仅支持 URL 方式
- **GLM-4.6V-Flash** 和 **GLM-4.1V-Thinking-Flash** 支持最多 **50 张图片**
- 图片大小限制：每张 5M 以下，像素不超过 6000x6000
- 支持格式：jpg, png, jpeg

**思考模式说明：**
- **GLM-4.6V-Flash**：支持 `thinking` 参数，启用后返回 `reasoning_content`
- **GLM-4.1V-Thinking-Flash**：强制思考，始终返回 `reasoning_content`
- **GLM-4V-Flash**：不支持思考模式

## 适用场景

1. **图像内容描述** - 自动为图片生成文字说明
2. **视觉问答** - 根据图片回答特定问题
3. **图片对比分析** - 比较多张图片的异同
4. **OCR 文字识别** - 提取图片中的文字内容
5. **图像分类与标签** - 识别图片中的物体和场景
6. **图表数据解读** - 理解并分析图表数据

## 图片格式和限制说明

### 支持的格式
- JPG/JPEG
- PNG

### 大小限制
- 单张图片大小：不超过 5MB
- 像素限制：不超过 6000x6000

### 数量限制
| 模型 | 单次请求最大图片数 |
|:---|:---:|
| GLM-4.6V-Flash | 50 张 |
| GLM-4.1V-Thinking-Flash | 50 张 |
| GLM-4V-Flash | **1 张** |

## API 调用方式

### 基本格式（image_url）

```python
import requests

API_KEY = "your-api-key"
API_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"

def vision_chat(model, image_url, prompt):
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": image_url}
                    }
                ]
            }
        ]
    }
    
    response = requests.post(API_URL, headers=headers, json=data)
    return response.json()
```

### 多张图片输入

```python
def vision_chat_multi(model, image_urls, prompt):
    """支持多张图片（仅限 GLM-4.6V-Flash 和 GLM-4.1V-Thinking-Flash）"""
    content = [{"type": "text", "text": prompt}]
    
    for url in image_urls:
        content.append({
            "type": "image_url",
            "image_url": {"url": url}
        })
    
    data = {
        "model": model,
        "messages": [{"role": "user", "content": content}]
    }
    # ... 发送请求
```

### 启用思考模式（GLM-4.6V-Flash）

```python
# GLM-4.6V-Flash 支持 thinking 参数
data = {
    "model": "glm-4.6v-flash",
    "messages": [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "分析这张图片的逻辑问题"},
                {"type": "image_url", "image_url": {"url": image_url}}
            ]
        }
    ],
    "thinking": {
        "type": "enabled"  # 启用思考模式
    }
}
```

## Base64 编码说明

**仅 GLM-4.6V-Flash 和 GLM-4.1V-Thinking-Flash 支持 Base64 编码。**

### Base64 格式

```python
import base64

def image_to_base64(image_path):
    """将本地图片转为 Base64 字符串"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

# 使用 Base64 调用
def vision_chat_base64(model, image_path, prompt):
    base64_image = image_to_base64(image_path)
    data = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ]
    }
    # ... 发送请求
```

## 代码示例

### GLM-4.6V-Flash 示例（支持思考模式）

```python
import requests

API_KEY = "your-api-key"
API_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"

# 基础图片理解
response = requests.post(API_URL, headers={
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}, json={
    "model": "glm-4.6v-flash",
    "messages": [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "描述这张图片的内容"},
                {
                    "type": "image_url",
                    "image_url": {"url": "https://example.com/image.jpg"}
                }
            ]
        }
    ]
})

result = response.json()
print(result["choices"][0]["message"]["content"])

# 启用思考模式进行深度分析
response_thinking = requests.post(API_URL, headers={
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}, json={
    "model": "glm-4.6v-flash",
    "messages": [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "分析这张图片中的细节和潜在含义"},
                {
                    "type": "image_url",
                    "image_url": {"url": "https://example.com/image.jpg"}
                }
            ]
        }
    ],
    "thinking": {"type": "enabled"}
})

result_thinking = response_thinking.json()
message = result_thinking["choices"][0]["message"]
print("思维链:", message.get("reasoning_content", "无"))
print("最终答案:", message["content"])
```

### GLM-4.1V-Thinking-Flash 示例（强制思考）

```python
# GLM-4.1V-Thinking-Flash 强制思考，始终输出 reasoning_content
response = requests.post(API_URL, headers={
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}, json={
    "model": "glm-4.1v-thinking-flash",
    "messages": [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "分析这张图片中的细节，并解释原因"},
                {
                    "type": "image_url",
                    "image_url": {"url": "https://example.com/image.jpg"}
                }
            ]
        }
    ]
})

result = response.json()
# 思考模型会输出 reasoning_content
print("推理过程:", result["choices"][0]["message"].get("reasoning_content", ""))
print("最终答案:", result["choices"][0]["message"]["content"])
```

### GLM-4V-Flash 示例

```python
# GLM-4V-Flash 仅支持单张图片，不支持 Base64，不支持思考模式
response = requests.post(API_URL, headers={
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}, json={
    "model": "glm-4v-flash",
    "messages": [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "这张图是什么？"},
                {
                    "type": "image_url",
                    "image_url": {"url": "https://example.com/image.jpg"}
                }
                # ⚠️ 注意：不能添加第二张图片，否则会报错
            ]
        }
    ],
    "max_tokens": 1000  # 该模型最大输出仅 1K
})
```

## 注意事项

1. **图片数量限制**
   - 使用 GLM-4V-Flash 时，**只能传入 1 张图片**，传入多张会报错
   - GLM-4.6V-Flash 和 GLM-4.1V-Thinking-Flash 最多支持 50 张图片

2. **Base64 支持**
   - GLM-4V-Flash **不支持 Base64**，只能使用 URL 方式
   - GLM-4.6V-Flash 和 GLM-4.1V-Thinking-Flash 支持 Base64 编码

3. **思考模式选择**
   - 需要深度分析：使用 GLM-4.6V-Flash + thinking 参数，或 GLM-4.1V-Thinking-Flash
   - 简单快速识别：使用 GLM-4V-Flash
   - 多图分析：使用 GLM-4.6V-Flash 或 GLM-4.1V-Thinking-Flash

4. **输出长度限制**
   - GLM-4V-Flash 最大输出仅 1K tokens，适合简短回答
   - GLM-4.6V-Flash 最大输出 32K，适合详细分析
   - GLM-4.1V-Thinking-Flash 最大输出 16K

5. **图片质量**
   - 图片清晰度会影响识别效果
   - 文字较小的图片建议提高分辨率

6. **错误处理**
   - 无效的图片 URL 会返回 400 错误
   - 超过数量限制会返回明确的错误信息
   - 图片格式不支持时会返回格式错误

7. **成本考虑**
   - 图片理解消耗更多的 tokens
   - 多张图片的请求成本会显著增加
