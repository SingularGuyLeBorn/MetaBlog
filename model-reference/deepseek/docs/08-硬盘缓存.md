# 12-硬盘缓存（KV Cache）

来源：https://api-docs.deepseek.com/zh-cn/guides/kv_cache

## 概述

DeepSeek API 支持**硬盘缓存**（KV Cache）机制。如果输入的**前缀**与之前的请求相同，系统可以复用缓存，大幅降低 token 费用。

## 缓存命中 vs 未命中

| 类型 | 价格 | 说明 |
|:---|:---:|:---|
| 缓存命中 | ¥0.2/百万 tokens | 输入前缀与缓存匹配 |
| 缓存未命中 | ¥2/百万 tokens | 输入前缀与缓存不匹配 |

**节省高达 90% 费用！**

## 缓存机制

- **前缀匹配**：系统只匹配用户输入的前缀部分
- **输出仍计算**：输出部分仍然通过推理计算，受 temperature 等参数影响
- **效果一致**：缓存命中后的输出效果与不使用缓存相同

## 典型应用场景

### 1. 固定 System Prompt

```python
# 每次请求相同的 system prompt
messages = [
    {"role": "system", "content": "你是一位资深的财报分析师..."},
    {"role": "user", "content": "<财报内容>\n\n请总结一下这份财报的关键信息。"}
]

# 第二个请求复用 system prompt 缓存
messages2 = [
    {"role": "system", "content": "你是一位资深的财报分析师..."},  # 命中缓存！
    {"role": "user", "content": "<财报内容>\n\n请分析一下这份财报的盈利情况。"}
]
```

### 2. 多轮对话

```python
messages = [
    {"role": "system", "content": "你是一位乐于助人的助手"},  # 命中缓存
    {"role": "user", "content": "中国的首都是哪里？"},
    {"role": "assistant", "content": "中国的首都是北京。"},  # 命中缓存
    {"role": "user", "content": "美国的首都是哪里？"}  # 前面的内容都命中缓存
]
```

### 3. Few-shot 学习

```python
# Few-shot 示例可以缓存，大幅降低费用
messages = [
    {"role": "system", "content": "你是一位历史学专家，回答以`Answer:`开头"},
    {"role": "user", "content": "秦始皇统一六国是哪一年？"},
    {"role": "assistant", "content": "Answer:公元前221年"},  # 缓存
    {"role": "user", "content": "汉朝的建立者是谁？"},
    {"role": "assistant", "content": "Answer:刘邦"},  # 缓存
    {"role": "user", "content": "唐朝最后一任皇帝是谁？"},
    {"role": "assistant", "content": "Answer:李柷"},  # 缓存
    {"role": "user", "content": "明朝的开国皇帝是谁？"},
    {"role": "assistant", "content": "Answer:朱元璋"},  # 缓存
    {"role": "user", "content": "清朝的开国皇帝是谁？"}  # 前面大量缓存命中
]
```

## 最佳实践

1. **固定前缀**：将不变的 system prompt 放在最前面
2. **复用历史**：多轮对话中保留完整历史
3. **批量相似请求**：将相似的请求批量发送，提高缓存命中率

## 注意事项

- 缓存基于**前缀匹配**，必须从头开始匹配
- 输出部分**不参与缓存**，每次都重新计算
- temperature、top_p 等参数仍然会影响输出
