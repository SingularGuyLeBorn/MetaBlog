# DeepSeek é›†æˆæŒ‡å—

é¡¹ç›®å·²å†…ç½® DeepSeek æ”¯æŒï¼Œåªéœ€é…ç½®å³å¯ä½¿ç”¨ã€‚

## 1. é…ç½® .env æ–‡ä»¶

åœ¨é¡¹ç›®æ ¹ç›®å½• `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```bash
# DeepSeek é…ç½®
VITE_DEEPSEEK_API_KEY=your-deepseek-api-key
VITE_DEEPSEEK_BASE_URL=https://api.deepseek.com
VITE_DEEPSEEK_MODEL=deepseek-chat  # æˆ– deepseek-reasoner

# è®¾ç½®é»˜è®¤ä½¿ç”¨ DeepSeek
VITE_LLM_DEFAULT_PROVIDER=deepseek
```

## 2. å‰ç«¯èŠå¤©ç»„ä»¶ç¤ºä¾‹

### åŸºç¡€èŠå¤©ç»„ä»¶

```vue
<template>
  <div class="chat-container">
    <!-- æ¶ˆæ¯åˆ—è¡¨ -->
    <div class="messages">
      <div 
        v-for="msg in messages" 
        :key="msg.id"
        :class="['message', msg.role]"
      >
        <div class="avatar">{{ msg.role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–' }}</div>
        <div class="content">
          <div v-if="msg.reasoning" class="reasoning">
            ğŸ’­ {{ msg.reasoning }}
          </div>
          <div class="text">{{ msg.content }}</div>
        </div>
      </div>
      
      <!-- åŠ è½½çŠ¶æ€ -->
      <div v-if="isLoading" class="message assistant loading">
        <div class="avatar">ğŸ¤–</div>
        <div class="content">æ€è€ƒä¸­...</div>
      </div>
    </div>
    
    <!-- è¾“å…¥æ¡† -->
    <div class="input-area">
      <textarea
        v-model="userInput"
        @keydown.enter.prevent="sendMessage"
        placeholder="è¾“å…¥æ¶ˆæ¯..."
        :disabled="isLoading"
      />
      <button @click="sendMessage" :disabled="isLoading || !userInput.trim()">
        å‘é€
      </button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted } from 'vue'
import { getLLMManager } from '../llm'

const messages = ref<Array<{
  id: string
  role: 'user' | 'assistant'
  content: string
  reasoning?: string
}>>([])

const userInput = ref('')
const isLoading = ref(false)

// è·å– LLM Manager
const llm = getLLMManager()

// å‘é€æ¶ˆæ¯
async function sendMessage() {
  const content = userInput.value.trim()
  if (!content || isLoading.value) return
  
  // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  messages.value.push({
    id: Date.now().toString(),
    role: 'user',
    content
  })
  
  userInput.value = ''
  isLoading.value = true
  
  try {
    // ä½¿ç”¨ DeepSeek å‘é€è¯·æ±‚
    const response = await llm.chat('deepseek', {
      messages: messages.value.map(m => ({
        role: m.role,
        content: m.content
      })),
      model: 'deepseek-chat',  // æˆ– 'deepseek-reasoner'
      temperature: 0.7,
      maxTokens: 4096
    })
    
    // æ·»åŠ åŠ©æ‰‹å›å¤
    messages.value.push({
      id: (Date.now() + 1).toString(),
      role: 'assistant',
      content: response.content
    })
    
  } catch (error) {
    console.error('Chat error:', error)
    messages.value.push({
      id: (Date.now() + 1).toString(),
      role: 'assistant',
      content: 'âŒ å‘é€å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®'
    })
  } finally {
    isLoading.value = false
  }
}

// æµå¼èŠå¤©
async function sendMessageStream() {
  const content = userInput.value.trim()
  if (!content || isLoading.value) return
  
  messages.value.push({
    id: Date.now().toString(),
    role: 'user',
    content
  })
  
  userInput.value = ''
  isLoading.value = true
  
  // åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å ä½
  const assistantMsg = {
    id: (Date.now() + 1).toString(),
    role: 'assistant' as const,
    content: ''
  }
  messages.value.push(assistantMsg)
  
  try {
    await llm.chatStream(
      'deepseek',
      {
        messages: messages.value
          .filter(m => m.role !== 'assistant' || m.content !== '')
          .map(m => ({ role: m.role, content: m.content })),
        model: 'deepseek-chat',
        stream: true
      },
      (chunk) => {
        // å®æ—¶æ›´æ–°æ¶ˆæ¯å†…å®¹
        assistantMsg.content += chunk.content
      }
    )
  } catch (error) {
    console.error('Stream error:', error)
    assistantMsg.content = 'âŒ å‘é€å¤±è´¥'
  } finally {
    isLoading.value = false
  }
}
</script>

<style scoped>
.chat-container {
  display: flex;
  flex-direction: column;
  height: 100%;
}

.messages {
  flex: 1;
  overflow-y: auto;
  padding: 16px;
}

.message {
  display: flex;
  gap: 12px;
  margin-bottom: 16px;
}

.message.user {
  flex-direction: row-reverse;
}

.avatar {
  width: 40px;
  height: 40px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  background: #f0f0f0;
}

.content {
  max-width: 70%;
  padding: 12px 16px;
  border-radius: 12px;
  background: #f5f5f5;
}

.message.user .content {
  background: #007bff;
  color: white;
}

.reasoning {
  font-size: 12px;
  color: #666;
  margin-bottom: 8px;
  padding: 8px;
  background: #fafafa;
  border-radius: 8px;
}

.input-area {
  display: flex;
  gap: 8px;
  padding: 16px;
  border-top: 1px solid #e0e0e0;
}

textarea {
  flex: 1;
  padding: 12px;
  border: 1px solid #ddd;
  border-radius: 8px;
  resize: none;
  height: 60px;
}

button {
  padding: 12px 24px;
  background: #007bff;
  color: white;
  border: none;
  border-radius: 8px;
  cursor: pointer;
}

button:disabled {
  background: #ccc;
}
</style>
</template>
```

### ä½¿ç”¨ DeepSeek Reasonerï¼ˆæ€è€ƒæ¨¡å¼ï¼‰

```typescript
import { getLLMManager } from '../llm'

const llm = getLLMManager()

// ä½¿ç”¨ deepseek-reasonerï¼ˆä¼šè¿”å›æ€è€ƒè¿‡ç¨‹ï¼‰
async function chatWithReasoning() {
  const response = await llm.chat('deepseek', {
    messages: [{ role: 'user', content: 'è§£æ–¹ç¨‹ 2x + 5 = 13' }],
    model: 'deepseek-reasoner',  // æ€è€ƒæ¨¡å¼
    maxTokens: 8192  // reasoner æ”¯æŒæ›´é•¿è¾“å‡º
  })
  
  // å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹
  if (response.reasoningContent) {
    console.log('æ€è€ƒè¿‡ç¨‹:', response.reasoningContent)
  }
  
  console.log('æœ€ç»ˆç­”æ¡ˆ:', response.content)
}
```

## 3. åœ¨ Agent ä¸­ä½¿ç”¨

```typescript
import { AgentRuntime } from './core/AgentRuntime'

// è·å– Agent å®ä¾‹
const agent = AgentRuntime.getInstance({
  mode: 'COLLAB',
  enableCostTracking: true
})

// å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆè‡ªåŠ¨ä½¿ç”¨é…ç½®çš„ DeepSeekï¼‰
async function handleUserInput(input: string) {
  const response = await agent.processInput(input, {
    currentFile: 'article.md'
  })
  
  console.log('Agent å›å¤:', response.content)
  console.log('Token æ¶ˆè€—:', response.metadata?.tokens)
  console.log('æˆæœ¬:', response.metadata?.cost)
}
```

## 4. ç›´æ¥ä½¿ç”¨ Provider

```typescript
import { DeepSeekProvider } from './llm/providers/deepseek'

const deepseek = new DeepSeekProvider({
  apiKey: import.meta.env.VITE_DEEPSEEK_API_KEY,
  baseURL: 'https://api.deepseek.com',
  model: 'deepseek-chat',
  temperature: 0.7,
  maxTokens: 4096
})

// æ™®é€šèŠå¤©
const response = await deepseek.chat({
  messages: [{ role: 'user', content: 'Hello!' }]
})

// æµå¼èŠå¤©
await deepseek.chatStream(
  { messages: [...] },
  (chunk) => {
    console.log(chunk.content)  // å®æ—¶è¾“å‡º
  }
)
```

## 5. å¯ç”¨çš„ DeepSeek æ¨¡å‹

| æ¨¡å‹ | è¯´æ˜ | è¾“å‡ºé•¿åº¦ |
|:---|:---|:---:|
| `deepseek-chat` | æ—¥å¸¸å¯¹è¯ï¼Œå¿«é€Ÿå“åº” | 8K |
| `deepseek-coder` | ä»£ç ç”Ÿæˆ | 8K |
| `deepseek-reasoner` | æ·±åº¦æ¨ç†ï¼Œæ€ç»´é“¾ | 64K |

## 6. ä»·æ ¼å‚è€ƒ

| ç±»å‹ | ä»·æ ¼ï¼ˆäººæ°‘å¸ï¼‰ |
|:---|:---|
| è¾“å…¥ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰ | Â¥0.2/ç™¾ä¸‡ tokens |
| è¾“å…¥ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰ | Â¥2/ç™¾ä¸‡ tokens |
| è¾“å‡º | Â¥3/ç™¾ä¸‡ tokens |

## 7. æ•…éšœæ’æŸ¥

### API Key æ— æ•ˆ
```
âŒ é”™è¯¯ï¼š401 Unauthorized
âœ… è§£å†³ï¼šæ£€æŸ¥ .env ä¸­çš„ VITE_DEEPSEEK_API_KEY æ˜¯å¦æ­£ç¡®
```

### æ¨¡å‹ä¸å­˜åœ¨
```
âŒ é”™è¯¯ï¼šModel not found
âœ… è§£å†³ï¼šç¡®è®¤æ¨¡å‹åç§°ä¸º deepseek-chat æˆ– deepseek-reasoner
```

### ç½‘ç»œé”™è¯¯
```
âŒ é”™è¯¯ï¼šNetwork error
âœ… è§£å†³ï¼šæ£€æŸ¥ VITE_DEEPSEEK_BASE_URL æ˜¯å¦ä¸º https://api.deepseek.com
```

## 8. å®Œæ•´ç¤ºä¾‹

æŸ¥çœ‹ `theme/components/AIChatOrb.vue` è·å–å®Œæ•´çš„å‰ç«¯èŠå¤©å®ç°ã€‚
